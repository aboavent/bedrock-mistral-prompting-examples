{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f89013e3-3585-486a-87e5-c234ec6a816e",
   "metadata": {},
   "source": [
    "# Mistral Large 2 (24.07) Deeper Dive\n",
    "\n",
    "Mistral Large 2 is an advanced large language model with state-of-the-art reasoning, knowledge, and coding capabilities according to Mistral. Mistral Large 2 is designed for single-node inference with long-context applications in mind â€“ its size of 123 billion parameters allows it to run at large throughput on a single node. A significant effort was also devoted by Mistral to enhancing the model's reasoning capabilities. One of Mistral's key focuses during training was to minimize the model's tendency to \"hallucinate,\" or generate plausible-sounding but factually incorrect or irrelevant information. This was achieved by fine-tuning the model to be more cautious and discerning in its responses, ensuring that it provides reliable and accurate outputs. Additionally, the new Mistral Large is trained to acknowledge when it cannot find solutions or does not have sufficient information to provide a confident answer. Mistral Large 2 sets a new frontier in terms of performance / cost of serving on evaluation metrics. In particular, on MMLU, the pretrained version achieves an accuracy of 84.0%, and sets a new point on the performance/cost Pareto front of open models.\n",
    "\n",
    "The model is currently generally available for use on Amazon Bedrock, check out the blog post for more info.\n",
    "\n",
    "In this notebook we will be demonstrating python generation, language translation and assessment and tool use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d17a438-b854-42f1-a02d-11eae0222227",
   "metadata": {},
   "source": [
    "## Model Card\n",
    "\n",
    "Available regions: US-West-2\n",
    "\n",
    "Model ID: mistral.mistral-large-2407-v1:0\n",
    "\n",
    "Context Window : 128k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e46cb3-1245-476a-ba0a-eeb524b3ac00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from boto3 import client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a15b77-e0fe-4c08-81ff-8061850f5c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_client = boto3.client(service_name='bedrock-runtime', region_name=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ceb82f6-0b56-4fb8-ac30-404b7a44e7cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mistral_large_2 = 'mistral.mistral-large-2407-v1:0'\n",
    "mistral_large_1 = 'mistral.mistral-large-2402-v1:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b90e9-8f76-4216-a359-c4075c313a18",
   "metadata": {},
   "source": [
    "## Python Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2770e6e-7b4a-45ac-93e7-ad70134f141d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def converse(prompt, model_id=mistral_large_2, max_tokens=3000, temperature=0.1, top_p=0.9):\n",
    "    body = json.dumps({\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p\n",
    "    })\n",
    "    \n",
    "    response = bedrock_client.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=body\n",
    "    )\n",
    "    \n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    generated_text = response_body.get('outputs', [{}])[0].get('text', '')\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f565bd-1592-4527-8283-249e4d8d0bc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "```python\n",
      "# Import necessary libraries\n",
      "import yfinance as yf\n",
      "import pandas as pd\n",
      "import plotly.graph_objs as go\n",
      "from plotly.subplots import make_subplots\n",
      "import ipywidgets as widgets\n",
      "from IPython.display import display\n",
      "\n",
      "# Function to fetch stock data\n",
      "def fetch_stock_data(ticker, period='6mo'):\n",
      "    try:\n",
      "        stock_data = yf.download(ticker, period=period)\n",
      "        return stock_data\n",
      "    except Exception as e:\n",
      "        print(f\"Error fetching data for {ticker}: {e}\")\n",
      "        return pd.DataFrame()\n",
      "\n",
      "# Function to calculate daily returns\n",
      "def calculate_daily_returns(stock_data):\n",
      "    stock_data['Daily Return'] = stock_data['Adj Close'].pct_change()\n",
      "    return stock_data\n",
      "\n",
      "# Function to compute 20-day moving average\n",
      "def compute_moving_average(stock_data, window=20):\n",
      "    stock_data[f'{window}-Day MA'] = stock_data['Adj Close'].rolling(window=window).mean()\n",
      "    return stock_data\n",
      "\n",
      "# Fetch data for NVDA and AAPL\n",
      "nvda_data = fetch_stock_data('NVDA')\n",
      "aapl_data = fetch_stock_data('AAPL')\n",
      "\n",
      "# Calculate daily returns and moving averages\n",
      "nvda_data = calculate_daily_returns(nvda_data)\n",
      "aapl_data = calculate_daily_returns(aapl_data)\n",
      "nvda_data = compute_moving_average(nvda_data)\n",
      "aapl_data = compute_moving_average(aapl_data)\n",
      "\n",
      "# Create interactive visualizations\n",
      "def create_line_chart(nvda_data, aapl_data):\n",
      "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
      "\n",
      "    # NVDA data\n",
      "    fig.add_trace(go.Scatter(x=nvda_data.index, y=nvda_data['Adj Close'], mode='lines', name='NVDA Adj Close'), row=1, col=1)\n",
      "    fig.add_trace(go.Scatter(x=nvda_data.index, y=nvda_data['20-Day MA'], mode='lines', name='NVDA 20-Day MA'), row=1, col=1)\n",
      "\n",
      "    # AAPL data\n",
      "    fig.add_trace(go.Scatter(x=aapl_data.index, y=aapl_data['Adj Close'], mode='lines', name='AAPL Adj Close'), row=2, col=1)\n",
      "    fig.add_trace(go.Scatter(x=aapl_data.index, y=aapl_data['20-Day MA'], mode='lines', name='AAPL 20-Day MA'), row=2, col=1)\n",
      "\n",
      "    fig.update_layout(height=600, width=800, title_text=\"NVDA and AAPL Stock Performance and 20-Day Moving Averages\")\n",
      "    return fig\n",
      "\n",
      "def create_bar_chart(stock_data, stock_name):\n",
      "    fig = go.Figure(data=[go.Bar(x=stock_data.index, y=stock_data['Daily Return'], name=f'{stock_name} Daily Return')])\n",
      "    fig.update_layout(title_text=f'{stock_name} Daily Returns', xaxis_title='Date', yaxis_title='Daily Return')\n",
      "    return fig\n",
      "\n",
      "# Dropdown menu to select stock\n",
      "stock_dropdown = widgets.Dropdown(\n",
      "    options=[('NVDA', nvda_data), ('AAPL', aapl_data)],\n",
      "    value=nvda_data,\n",
      "    description='Stock:',\n",
      "    disabled=False,\n",
      ")\n",
      "\n",
      "# Button to refresh data\n",
      "refresh_button = widgets.Button(description=\"Refresh Data\")\n",
      "\n",
      "# Function to update charts\n",
      "def update_charts(change):\n",
      "    selected_stock = stock_dropdown.value\n",
      "    stock_name = stock_dropdown.label\n",
      "    bar_chart = create_bar_chart(selected_stock, stock_name)\n",
      "    display(bar_chart)\n",
      "\n",
      "# Function to refresh data\n",
      "def refresh_data(button):\n",
      "    global nvda_data, aapl_data\n",
      "    nvda_data = fetch_stock_data('NVDA')\n",
      "    aapl_data = fetch_stock_data('AAPL')\n",
      "    nvda_data = calculate_daily_returns(nvda_data)\n",
      "    aapl_data = calculate_daily_returns(aapl_data)\n",
      "    nvda_data = compute_moving_average(nvda_data)\n",
      "    aapl_data = compute_moving_average(aapl_data)\n",
      "    stock_dropdown.options = [('NVDA', nvda_data), ('AAPL', aapl_data)]\n",
      "    update_charts(None)\n",
      "\n",
      "# Register callbacks\n",
      "stock_dropdown.observe(update_charts, names='value')\n",
      "refresh_button.on_click(refresh_data)\n",
      "\n",
      "# Display widgets and initial charts\n",
      "display(stock_dropdown)\n",
      "display(refresh_button)\n",
      "line_chart = create_line_chart(nvda_data, aapl_data)\n",
      "display(line_chart)\n",
      "update_charts(None)\n",
      "```\n",
      "\n",
      "This script sets up a Jupyter notebook environment to fetch stock data for NVDA and AAPL, perform basic analysis, and create interactive visualizations using Plotly and ipywidgets. The dropdown menu allows users to select which stock's daily returns to display, and the refresh button updates the data. Error handling is included to manage potential issues with API calls and data processing.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Create a Python script for a Jupyter notebook that fetches stock market data for NVIDIA (NVDA) and Apple (AAPL) and performs analysis with interactive visualizations. The script should:\n",
    "\n",
    "Use the yfinance library to fetch stock data for NVDA and AAPL for the last 6 months.\n",
    "Implement data analysis functions to:\n",
    "\n",
    "Calculate daily returns\n",
    "Compute 20-day moving average\n",
    "\n",
    "\n",
    "Create interactive visualizations using Plotly, including:\n",
    "\n",
    "A line chart comparing both stocks' performance and their 20-day moving averages\n",
    "A bar chart showing daily returns for the selected stock\n",
    "\n",
    "\n",
    "Use ipywidgets to create:\n",
    "\n",
    "A dropdown menu to select which stock to display in the bar chart\n",
    "A button to refresh the data\n",
    "\n",
    "\n",
    "Include error handling for API calls and data processing.\n",
    "Add brief comments explaining key parts of the code.\n",
    "\n",
    "The final output should be a single Python script that can be run in a Jupyter notebook cell, creating an interactive dashboard for stock analysis of NVDA and AAPL.\n",
    "Ensure all necessary libraries are imported at the beginning of the script. The code should be well-structured and follow Python best practices.\n",
    "Note: Real-time updating is not required; fetching data once when the script runs and on button click is sufficient.\n",
    "\"\"\"\n",
    "\n",
    "generated_text = converse(prompt)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440365b0-efd4-4ea6-8a24-3a22f2347217",
   "metadata": {},
   "source": [
    "Python generated by Large 2 below, or feel free to run the cell above to get the same or similar completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9394577-a004-4d60-b2d0-b1ce1c6fb02e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Large 2 generated \n",
    "# Import necessary libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Function to fetch stock data\n",
    "def fetch_stock_data(ticker, period='6mo'):\n",
    "    try:\n",
    "        stock_data = yf.download(ticker, period=period)\n",
    "        return stock_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to calculate daily returns\n",
    "def calculate_daily_returns(stock_data):\n",
    "    stock_data['Daily Return'] = stock_data['Adj Close'].pct_change()\n",
    "    return stock_data\n",
    "\n",
    "# Function to compute 20-day moving average\n",
    "def compute_moving_average(stock_data, window=20):\n",
    "    stock_data[f'{window}-Day MA'] = stock_data['Adj Close'].rolling(window=window).mean()\n",
    "    return stock_data\n",
    "\n",
    "# Fetch data for NVDA and AAPL\n",
    "nvda_data = fetch_stock_data('NVDA')\n",
    "aapl_data = fetch_stock_data('AAPL')\n",
    "\n",
    "# Calculate daily returns and moving averages\n",
    "nvda_data = calculate_daily_returns(nvda_data)\n",
    "aapl_data = calculate_daily_returns(aapl_data)\n",
    "nvda_data = compute_moving_average(nvda_data)\n",
    "aapl_data = compute_moving_average(aapl_data)\n",
    "\n",
    "# Function to create line chart\n",
    "def create_line_chart(nvda_data, aapl_data):\n",
    "    fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=nvda_data.index, y=nvda_data['Adj Close'], mode='lines', name='NVDA'))\n",
    "    fig.add_trace(go.Scatter(x=nvda_data.index, y=nvda_data['20-Day MA'], mode='lines', name='NVDA 20-Day MA'))\n",
    "    fig.add_trace(go.Scatter(x=aapl_data.index, y=aapl_data['Adj Close'], mode='lines', name='AAPL'))\n",
    "    fig.add_trace(go.Scatter(x=aapl_data.index, y=aapl_data['20-Day MA'], mode='lines', name='AAPL 20-Day MA'))\n",
    "\n",
    "    fig.update_layout(title='NVDA and AAPL Stock Performance', xaxis_title='Date', yaxis_title='Price')\n",
    "    return fig\n",
    "\n",
    "# Function to create bar chart\n",
    "def create_bar_chart(stock_data, ticker):\n",
    "    fig = go.Figure(data=[go.Bar(x=stock_data.index, y=stock_data['Daily Return'], name=ticker)])\n",
    "    fig.update_layout(title=f'{ticker} Daily Returns', xaxis_title='Date', yaxis_title='Daily Return')\n",
    "    return fig\n",
    "\n",
    "# Dropdown menu to select stock\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=[('NVDA', 'NVDA'), ('AAPL', 'AAPL')],\n",
    "    value='NVDA',\n",
    "    description='Stock:'\n",
    ")\n",
    "\n",
    "# Button to refresh data\n",
    "button = widgets.Button(description=\"Refresh Data\")\n",
    "\n",
    "# Output widgets for charts\n",
    "line_chart_output = widgets.Output()\n",
    "bar_chart_output = widgets.Output()\n",
    "\n",
    "# Function to update charts\n",
    "def update_charts(change):\n",
    "    with line_chart_output:\n",
    "        line_chart_output.clear_output()\n",
    "        fig = create_line_chart(nvda_data, aapl_data)\n",
    "        fig.show()\n",
    "\n",
    "    with bar_chart_output:\n",
    "        bar_chart_output.clear_output()\n",
    "        selected_stock = dropdown.value\n",
    "        if selected_stock == 'NVDA':\n",
    "            fig = create_bar_chart(nvda_data, 'NVDA')\n",
    "        else:\n",
    "            fig = create_bar_chart(aapl_data, 'AAPL')\n",
    "        fig.show()\n",
    "\n",
    "# Function to refresh data\n",
    "def refresh_data(button):\n",
    "    global nvda_data, aapl_data\n",
    "    nvda_data = fetch_stock_data('NVDA')\n",
    "    aapl_data = fetch_stock_data('AAPL')\n",
    "    nvda_data = calculate_daily_returns(nvda_data)\n",
    "    aapl_data = calculate_daily_returns(aapl_data)\n",
    "    nvda_data = compute_moving_average(nvda_data)\n",
    "    aapl_data = compute_moving_average(aapl_data)\n",
    "    update_charts(None)\n",
    "\n",
    "# Register button click event\n",
    "button.on_click(refresh_data)\n",
    "\n",
    "# Initial chart display\n",
    "update_charts(None)\n",
    "\n",
    "# Display widgets\n",
    "display(dropdown, button, line_chart_output, bar_chart_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318d94cb-f01a-43c2-98b1-04e2a79c70a1",
   "metadata": {},
   "source": [
    "## Language Translation Performance\n",
    "\n",
    "Large 1 & Large 2 Japanese translation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e3b94-bb50-4d55-b148-af36bdfec6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_models(prompt, model_1=mistral_large_1, model_2=mistral_large_2, max_tokens=1000, temperature=0.1, top_p=0.9):\n",
    "    result_1 = converse(prompt, model_id=model_1, max_tokens=max_tokens, temperature=temperature, top_p=top_p)\n",
    "    result_2 = converse(prompt, model_id=model_2, max_tokens=max_tokens, temperature=temperature, top_p=top_p)\n",
    "    \n",
    "    return {\n",
    "        f\"{model_1}\": result_1,\n",
    "        f\"{model_2}\": result_2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc772961-0b3f-4f26-90af-48df587ebeb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "language_input = \"\"\"\n",
    "Quantum Entanglement: Spooky Action at a Distance\n",
    "\n",
    "Quantum entanglement is a phenomenon where two particles become connected in such a way that the quantum state of each particle cannot be described independently, even when separated by a large distance. Einstein famously referred to this as 'spooky action at a distance.'\n",
    "Key points:\n",
    "\n",
    "Entangled particles react instantaneously to their partner's state changes.\n",
    "This seems to violate the speed of light limit for information transfer.\n",
    "It's fundamental to quantum computing and cryptography.\n",
    "Entanglement has been experimentally verified up to distances of 1,200 kilometers.\n",
    "\n",
    "Despite decades of research, the mechanism behind quantum entanglement remains one of the most perplexing aspects of quantum mechanics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab14dcc-b539-479c-b968-89bfebf45c90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "translation_prompt = f\"\"\"\n",
    "\n",
    "<<Text to translate>>\n",
    "\n",
    "{language_input}\n",
    "\n",
    "<<Instructions>>\n",
    "\n",
    "Translate the following text about quantum entanglement into Japanese only. Ensure the translation accurately conveys the scientific concepts and maintains the educational tone of the original text.\n",
    "\n",
    "Format the response as follows:\n",
    "\n",
    "Japanese:\n",
    "\"\"\"\n",
    "\n",
    "comparison_results = compare_models(translation_prompt)\n",
    "\n",
    "print(\"Mistral Large 1 Output:\")\n",
    "print(comparison_results[mistral_large_1])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Mistral Large 2 Output:\")\n",
    "print(comparison_results[mistral_large_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037c35e0-b084-43b5-91a6-5d00d9c56185",
   "metadata": {},
   "source": [
    "Compare Japanese translations using Large 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62bcd97-864c-4f40-8e41-63b9bbe902fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_prompt = f\"\"\"\n",
    "Compare the following two Japanese translations of the English text about quantum entanglement. Analyze them in terms of accuracy, naturalness, preservation of scientific terminology, and overall suitability for a scientific publication. Discuss the strengths and weaknesses of each translation together.\n",
    "\n",
    "Original English text:\n",
    "{language_input}\n",
    "\n",
    "Translation 1:\n",
    "{comparison_results[mistral_large_1]}\n",
    "\n",
    "Translation 2:\n",
    "{comparison_results[mistral_large_2]}\n",
    "\n",
    "Please structure your analysis as follows:\n",
    "1. Accuracy: How well does each translation convey the original meaning?\n",
    "2. Naturalness: How natural and fluent does the Japanese sound in each translation?\n",
    "3. Scientific Terminology: How well are scientific terms preserved and translated?\n",
    "4. Overall Suitability: Which translation would be more suitable for a scientific publication and why?\n",
    "5. Specific Differences: Highlight any notable differences between the two translations and discuss their impact.\n",
    "6. Conclusion: Summarize your findings and give your overall assessment of which translation is superior.\n",
    "\n",
    "Provide your analysis in English in an easy to read paragraph.\n",
    "\"\"\"\n",
    "\n",
    "comparison_analysis = converse(comparison_prompt, model_id=mistral_large_2, max_tokens=2000, temperature=0.1, top_p=0.9)\n",
    "print(comparison_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c9b79-d106-48a3-809d-42fc579abf5b",
   "metadata": {},
   "source": [
    "## Tool Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b2922-ccfa-4b45-9c08-95673567800f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tool_config = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"shinkansen_schedule\",\n",
    "                \"description\": \"Fetches Shinkansen train schedule departure times for a specified station and time.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"station\": {\"type\": \"string\", \"description\": \"The station name.\"},\n",
    "                            \"departure_time\": {\"type\": \"string\", \"description\": \"The departure time in HH:MM format.\"}\n",
    "                        },\n",
    "                        \"required\": [\"station\", \"departure_time\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"weather_forecast\",\n",
    "                \"description\": \"Fetches the weather forecast for a specified city and date.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"city\": {\"type\": \"string\", \"description\": \"The city name.\"},\n",
    "                            \"date\": {\"type\": \"string\", \"description\": \"The date in YYYY-MM-DD format.\"}\n",
    "                        },\n",
    "                        \"required\": [\"city\", \"date\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72defee9-9f89-4a2e-af3c-fe2b1c20fb19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shinkansen_schedule(station, departure_time):\n",
    "    schedule = {\n",
    "        \"Tokyo\": {\"09:00\": \"Hikari\", \"12:00\": \"Nozomi\", \"15:00\": \"Kodama\"},\n",
    "        \"Osaka\": {\"10:00\": \"Nozomi\", \"13:00\": \"Hikari\", \"16:00\": \"Kodama\"}\n",
    "    }\n",
    "    return schedule.get(station, {}).get(departure_time, \"No train found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b2d87a-da50-4cee-bc2f-15eb996decef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weather_forecast(city, date):\n",
    "    forecast = {\n",
    "        \"Tokyo\": {\"2023-06-12\": \"Sunny\", \"2023-06-13\": \"Rainy\"},\n",
    "        \"Osaka\": {\"2023-06-12\": \"Cloudy\", \"2023-06-13\": \"Sunny\"}\n",
    "    }\n",
    "    return forecast.get(city, {}).get(date, \"No forecast found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599ff8a-b2ce-467c-8a38-b09755c4f53a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_tool_call(tool_name, tool_inputs):\n",
    "    if tool_name == \"shinkansen_schedule\":\n",
    "        return shinkansen_schedule(tool_inputs[\"station\"], tool_inputs[\"departure_time\"])\n",
    "    elif tool_name == \"weather_forecast\":\n",
    "        return weather_forecast(tool_inputs[\"city\"], tool_inputs[\"date\"])\n",
    "    else:\n",
    "        return f\"Unknown tool: {tool_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe7b78-e9a7-4abf-aec2-5e6d9404b04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = 'mistral.mistral-large-2407-v1:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04dfd93-5173-42b6-be62-83c8fd7cf511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chatbot_interaction(user_message, bedrock_client):\n",
    "    print(f\"\\n{'='*50}\\nUser Message: {user_message}\\n{'='*50}\")\n",
    "\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_message}]\n",
    "    }]\n",
    "\n",
    "    while True:\n",
    "        converse_response = bedrock_client.converse(\n",
    "            modelId=MODEL_ID,\n",
    "            messages=messages,\n",
    "            inferenceConfig={\"maxTokens\": 4096},\n",
    "            toolConfig=tool_config\n",
    "        )\n",
    "        message = converse_response['output']['message']\n",
    "\n",
    "        print(f\"\\nResponse:\")\n",
    "        print(f\"Stop Reason: {converse_response['stopReason']}\")\n",
    "        print(f\"Content: {message['content']}\")\n",
    "\n",
    "        if converse_response['stopReason'] != \"tool_use\":\n",
    "            break\n",
    "\n",
    "        tool_results = []\n",
    "        for block in message['content']:\n",
    "            if 'toolUse' in block:\n",
    "                tool_use = block['toolUse']\n",
    "                tool_name = tool_use[\"name\"]\n",
    "                tool_input = tool_use[\"input\"]\n",
    "\n",
    "                print(f\"\\nTool Used: {tool_name}\")\n",
    "                print(f\"Tool Input:\")\n",
    "                print(json.dumps(tool_input, indent=2))\n",
    "\n",
    "                tool_result = process_tool_call(tool_name, tool_input)\n",
    "\n",
    "                print(f\"\\nTool Result:\")\n",
    "                print(json.dumps(tool_result, indent=2))\n",
    "\n",
    "                tool_results.append({\n",
    "                    \"toolResult\": {\n",
    "                        \"toolUseId\": tool_use['toolUseId'],\n",
    "                        \"content\": [{\"text\": str(tool_result)}],\n",
    "                    }\n",
    "                })\n",
    "\n",
    "        messages.extend([\n",
    "            {\"role\": \"assistant\", \"content\": message['content']},\n",
    "            {\"role\": \"user\", \"content\": tool_results},\n",
    "        ])\n",
    "\n",
    "    final_response = next(\n",
    "        (block['text'] for block in message['content'] if block.get('text')),\n",
    "        None,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nFinal Response: {final_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355136a0-5941-4eee-8917-73f26574979a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "result = chatbot_interaction(\"What train departs Osaka at 10:00 and what is the weather in Tokyo on 2023-06-12?\", bedrock_client)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
